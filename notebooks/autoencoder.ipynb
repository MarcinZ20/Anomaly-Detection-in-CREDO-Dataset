{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AUTOENCODER ANALYSIS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook contains exploratory analysis of the images from **CREDO** dataset. We use Autoencoders to find and detect anomalies in the given dataset. \n",
    "\n",
    "#### Dataset\n",
    "Dataset contains thousands of images of size **(60x60)** in **.png** format.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset, random_split\n",
    "from torchvision.transforms import v2\n",
    "from torchvision.io import read_image\n",
    "from torchvision.utils import make_grid\n",
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First step is to create a dataset, that will load images and feed them to the model. Since there are a lot of images here, we don't want to load them all at once - instead we use **batches**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImgDataset(Dataset):\n",
    "    def __init__(self, root_dir, transform=None):\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.image_files = [file for file in os.listdir(root_dir) if file.endswith(\".png\")]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img_path = os.path.join(self.root_dir, self.image_files[index])\n",
    "        image = read_image(img_path)\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we define some key properties like:\n",
    "- **transform** function - converts and normalizes image\n",
    "- **dataset** - creates dataset using class above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = v2.Compose([v2.ToImage(),\n",
    "                        v2.ToDtype(torch.float32),\n",
    "                        v2.Normalize(mean=[0.5], std=[0.5])\n",
    "                        ])\n",
    "dataset = ImgDataset( \n",
    "                     root_dir='../data/processed', \n",
    "                     transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max: 61.0\n",
      "Min: -1.0\n"
     ]
    }
   ],
   "source": [
    "print(f'Max: {dataset[30].max()}\\nMin: {dataset[30].min()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Last step is to divide the data into training & test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(0.9 * len(dataset))\n",
    "test_size = len(dataset) - train_size\n",
    "\n",
    "train_data, test_data = random_split(dataset, [train_size, test_size], \n",
    "                                     generator=torch.Generator().manual_seed(42))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_data, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_data, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing summary statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Images: 110000\n",
      "Train Size: 99000\n",
      "Test Size: 11000\n",
      "Image Format: .png\n",
      "Image Size: (60, 60)\n",
      "Image Dimensions: torch.Size([1, 60, 60])\n",
      "Image Max Value: 125.0\n",
      "Image Min Value: -1.0\n"
     ]
    }
   ],
   "source": [
    "# Calculate the number of images\n",
    "num_images = len(dataset)\n",
    "\n",
    "# Calculate the train and test sizes\n",
    "train_size = len(train_data)\n",
    "test_size = len(test_data)\n",
    "\n",
    "# Calculate the image max and min values\n",
    "image_max = dataset[0].max()\n",
    "image_min = dataset[0].min()\n",
    "\n",
    "# Get the image format and dimensions\n",
    "image_format = '.png'\n",
    "image_size = dataset[0].view(60, 60).numpy().shape\n",
    "image_dimensions = dataset[0].shape\n",
    "\n",
    "# Display the statistics\n",
    "print(f\"Number of Images: {num_images}\")\n",
    "print(f\"Train Size: {train_size}\")\n",
    "print(f\"Test Size: {test_size}\")\n",
    "print(f\"Image Format: {image_format}\")\n",
    "print(f\"Image Size: {image_size}\")\n",
    "print(f\"Image Dimensions: {image_dimensions}\")\n",
    "print(f\"Image Max Value: {image_max}\")\n",
    "print(f\"Image Min Value: {image_min}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's visualize some of the data we're dealing with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x800 with 6 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axes = plt.subplots(2, 3, figsize=(10, 8))\n",
    "\n",
    "for i, ax in enumerate(axes.flatten()):\n",
    "    random_index = random.randint(0, len(train_loader.dataset))\n",
    "    image = train_loader.dataset[random_index].view(60, 60).numpy()\n",
    "    ax.imshow(image, cmap='gray')\n",
    "    ax.set_title(f'Image {random_index}.png')\n",
    "    ax.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on the CPU\n"
     ]
    }
   ],
   "source": [
    "#  configuring device\n",
    "if torch.cuda.is_available():\n",
    "  device = torch.device('cuda:0')\n",
    "  print('Running on the GPU')\n",
    "else:\n",
    "  device = torch.device('cpu')\n",
    "  print('Running on the CPU')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model with linear layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now it's time to create the model which we will train to detect anomalies.\n",
    "Our sequential models consists of the following:\n",
    "1. Encoder - reduces dimensionality\n",
    "2. Decoder - expands dimensionality\n",
    "\n",
    "#### Encoder architecture\n",
    "- 5 linear layers (each one gradually reduces dimensionality until reaching size of 4)\n",
    "- 4 LeakyReLU activation functions. The follow linear layers and introduce non-linearity \n",
    "\n",
    "#### Decoder architecture\n",
    "- 5 linear layers (each one gradually expands dimensionality until reaching size of 4)\n",
    "- 4 LeakyReLU activation functions. The follow linear layers and introduce non-linearity \n",
    "- 1 Sigmoid activation function (Sigmoid), because images are normalized to [0, 1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Autoencoder(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "\n",
    "        super(Autoencoder, self).__init__()\n",
    "\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(60 * 60, 512),\n",
    "            nn.LeakyReLU(True),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.LeakyReLU(True), \n",
    "            nn.Linear(256, 128),\n",
    "            nn.LeakyReLU(True),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.LeakyReLU(True),\n",
    "            nn.Linear(64, 32),\n",
    "            nn.LeakyReLU(True),\n",
    "            nn.Linear(32, 16)\n",
    "        ) \n",
    "        \n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(16, 32),\n",
    "            nn.LeakyReLU(True),\n",
    "            nn.Linear(32, 64),\n",
    "            nn.LeakyReLU(True),\n",
    "            nn.Linear(64, 128),\n",
    "            nn.LeakyReLU(True), \n",
    "            nn.Linear(128, 256),\n",
    "            nn.LeakyReLU(True),\n",
    "            nn.Linear(256, 512),\n",
    "            nn.LeakyReLU(True),\n",
    "            nn.Linear(512, 60 * 60),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "        decoded = self.decoder(encoded)\n",
    "\n",
    "        return decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_lin = Autoencoder()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model with Convolutional layers\n",
    "As for the second model, we propose the same architecture as the first one, but instead of using linear layers, we swap them out with Convolutional ones.\n",
    "\n",
    "Since we're using basically the same architecture, we will have a clear understanding of the differences as well as the similarities of both models.\n",
    "\n",
    "It will also make the task of comparing them much easier and fair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AutoencoderConvolutional(nn.Module):\n",
    "\n",
    "    def __init__(self) -> None:\n",
    "        \n",
    "        super(AutoencoderConvolutional, self).__init__()\n",
    "\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(1, 16, kernel_size=3, stride=2),  # N, 16, 30, 30\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Conv2d(16, 32, kernel_size=3, stride=2),  # N, 32, 15, 15\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Conv2d(32, 64, kernel_size=3, stride=2),  # N, 64, 8, 8\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Conv2d(64, 128, kernel_size=3, stride=2),  # N, 128, 4, 4\n",
    "        )\n",
    "\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.ConvTranspose2d(128, 64, kernel_size=4, stride=2),  # N, 64, 8, 8\n",
    "            nn.LeakyReLU(),\n",
    "            nn.ConvTranspose2d(64, 32, kernel_size=4, stride=2),  # N, 32, 16, 16\n",
    "            nn.LeakyReLU(),\n",
    "            nn.ConvTranspose2d(32, 16, kernel_size=4, stride=2),  # N, 16, 32, 32\n",
    "            nn.LeakyReLU(),\n",
    "            nn.ConvTranspose2d(16, 1, kernel_size=4, stride=2),  # N, 1, 64, 64\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "        decoded = self.decoder(encoded)\n",
    "\n",
    "        return decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_conv = AutoencoderConvolutional()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we define some training parameters:\n",
    "- Number of epochs\n",
    "- Criterion\n",
    "- Learning rate\n",
    "- Weight decay\n",
    "- Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 15\n",
    "CRITERION = nn.MSELoss()\n",
    "LEARNING_RATE = 1e-3\n",
    "# Optimizers\n",
    "OPTIMIZER_LIN = optim.Adam(model_lin.parameters(), lr=LEARNING_RATE)\n",
    "OPTIMIZER_CONV = optim.Adam(model_conv.parameters(), lr=LEARNING_RATE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we train our model on the given data, with the use of parameters defined above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_linear = []\n",
    "losses = []\n",
    "\n",
    "for e in range(EPOCHS):\n",
    "    for img in train_loader:\n",
    "        img = img.reshape(-1, 60 * 60)\n",
    "        recon = model_lin(img)\n",
    "        loss = CRITERION(recon, img)\n",
    "\n",
    "        OPTIMIZER_LIN.zero_grad()\n",
    "        loss.backward()\n",
    "        OPTIMIZER_LIN.step()\n",
    "        \n",
    "    losses.append(loss.item())  \n",
    "    print(f'Epoch: {e + 1}, Loss: {loss.item():.4f}')\n",
    "    output_linear.append((e, img, recon))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 6  # Number of images you want to display\n",
    "plt.figure(figsize=(20, 4))\n",
    "for i in range(n):\n",
    "\n",
    "    ax = plt.subplot(2, n, i + 1)\n",
    "    plt.imshow(img[i].reshape(60, 60), cmap='gray')\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "\n",
    "    ax = plt.subplot(2, n, i + 1 + n)\n",
    "    plt.imshow(recon[i].detach().numpy().reshape(60, 60), cmap='gray')\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the reconstruction error for each image\n",
    "reconstruction_error = np.mean((np.power((recon.detach().numpy() - img.detach().numpy()), 2)), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reconstruction_error_df = pd.DataFrame({'reconstruction_error': reconstruction_error,\n",
    "                                        'true_class': [0] * len(reconstruction_error)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reconstruction_error_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(range(1, EPOCHS + 1), losses[-1].detach().numpy(), marker='o')\n",
    "plt.title('Autoencoder Training Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_examples = 6\n",
    "fig, axes = plt.subplots(num_examples, 2, figsize=(16, 6 * num_examples))\n",
    "\n",
    "for i in range(num_examples):\n",
    "    axes[i, 0].imshow(img[i].view(60, 60).numpy(),\n",
    "                      cmap='gray', \n",
    "                      aspect=plt.gca().set_aspect('equal'))\n",
    "    axes[i, 0].set_title('Original')\n",
    "\n",
    "    axes[i, 1].imshow(recon[i].view(60, 60).detach().numpy(), \n",
    "                      cmap='gray', \n",
    "                      aspect=plt.gca().set_aspect('equal'))\n",
    "    axes[i, 1].set_title('Reconstructed')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_weights = model_lin.encoder[0].weight.data\n",
    "\n",
    "num_features_to_visualize = 16\n",
    "fig, axes = plt.subplots(4, 4, figsize=(16, 16))\n",
    "\n",
    "for i in range(num_features_to_visualize):\n",
    "    ax = axes[i // 4, i % 4]\n",
    "    feature = encoder_weights[i].view(60, 60).detach().numpy()\n",
    "    ax.imshow(feature, cmap='gray')\n",
    "    ax.set_title(f'Feature {i + 1}')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate model accuracy\n",
    "accuracy = sum(reconstruction_error_df['true_class'] == 0) / len(reconstruction_error_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0.00085\n",
    "\n",
    "plt.plot(range(1, EPOCHS + 1), losses, marker='o')\n",
    "plt.axhline(y=threshold, color='r', linestyle='dashed')\n",
    "plt.title('Autoencoder Training Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_lin.eval()\n",
    "anomalies = []\n",
    "\n",
    "for img in test_loader:\n",
    "    img = img.reshape(-1, 60 * 60)\n",
    "    recon = model_lin(img)\n",
    "    loss = CRITERION(recon, img)\n",
    "\n",
    "    if loss.item() > threshold:\n",
    "        anomalies.append((img, recon, loss.item()))\n",
    "\n",
    "len(anomalies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_anomalies_to_visualize = min(len(anomalies), 3)\n",
    "fig, axes = plt.subplots(3, 2, figsize=(14, 7 * num_anomalies_to_visualize))\n",
    "\n",
    "for i in range(num_anomalies_to_visualize):\n",
    "    axes[i, 0].imshow(img[i].view(60, 60).numpy(), cmap='gray')\n",
    "    axes[i, 0].set_title('Original')\n",
    "\n",
    "    axes[i, 1].imshow(anomalies[0][0][i].view(60, 60).detach().numpy(), cmap='gray')\n",
    "    axes[i, 1].set_title(f'Reconstructed\\nLoss: {anomalies[i][2]:.4f}')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder = AutoencoderConvolutional()\n",
    "img = torch.randn(1, 1, 60, 60)\n",
    "conv1 = nn.Conv2d(1, 16, kernel_size=(3, 3), stride=(1, 1), padding=1)\n",
    "print(conv1(img).shape)\n",
    "conv2 = nn.Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=1)\n",
    "print(conv2(conv1(img)).shape)\n",
    "conv3 = nn.Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=1)\n",
    "print(conv3(conv2(conv1(img))).shape)\n",
    "conv4 = nn.Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=1)\n",
    "print(conv4(conv3(conv2(conv1(img)))).shape)\n",
    "conv5 = nn.Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=1)\n",
    "print(conv5(conv4(conv3(conv2(conv1(img))))).shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AutoencoderConvolutional(nn.Module):\n",
    "    def __init__(self) -> None:\n",
    "        super(AutoencoderConvolutional, self).__init__()\n",
    "\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(1, 16, kernel_size=3, stride=1, padding=1),  # 1, 16, 60, 60\n",
    "            nn.LeakyReLU(0.1),\n",
    "            nn.Conv2d(16, 32, kernel_size=3, stride=2, padding=1),  # 1, 32, 30, 30\n",
    "            nn.LeakyReLU(0.1),\n",
    "            nn.Conv2d(32, 64, kernel_size=3, stride=2, padding=1),  # 1, 64, 15, 15\n",
    "            nn.LeakyReLU(0.1),\n",
    "            nn.Conv2d(64, 128, kernel_size=3, stride=2, padding=1),  # 1, 128, 8, 8\n",
    "            nn.LeakyReLU(0.1),\n",
    "            nn.Conv2d(128, 128, kernel_size=1, stride=1, padding=1),  # 1, 128, 8, 8\n",
    "        )\n",
    "\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.ConvTranspose2d(128, 128, kernel_size=3, stride=1, padding=1), # N, 128, 8, 8\n",
    "            nn.LeakyReLU(0.1),\n",
    "            nn.ConvTranspose2d(128, 64, kernel_size=3, stride=2, padding=1),  # N, 64, 16, 16\n",
    "            nn.LeakyReLU(0.1),\n",
    "            nn.ConvTranspose2d(64, 32, kernel_size=3, stride=2, padding=1),  # N, 32, 32, 32\n",
    "            nn.LeakyReLU(0.1),\n",
    "            nn.ConvTranspose2d(32, 16, kernel_size=3, stride=2, padding=1),  # N, 16, 64, 64\n",
    "            nn.LeakyReLU(0.1),\n",
    "            nn.ConvTranspose2d(16, 1, kernel_size=3, stride=1, padding=1),  # N, 1, 64, 64\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "        decoded = self.decoder(encoded)\n",
    "\n",
    "        return decoded\n",
    "\n",
    "model_conv = AutoencoderConvolutional()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 10\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model_conv.to(device)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for data in train_loader:\n",
    "        inputs = data[0].to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model_conv(inputs)\n",
    "        loss = CRITERION(outputs, inputs)\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        OPTIMIZER_CONV.zero_grad()\n",
    "        loss.backward()\n",
    "        OPTIMIZER_CONV.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, in_channels=1, out_channels=16, latent_dim=200, act_fn=nn.LeakyReLU()):\n",
    "        super().__init__()\n",
    "\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, 3, padding=1), # (32, 32)\n",
    "            act_fn,\n",
    "            nn.Conv2d(out_channels, out_channels, 3, padding=1), \n",
    "            act_fn,\n",
    "            nn.Conv2d(out_channels, 2*out_channels, 3, padding=1, stride=2), # (16, 16)\n",
    "            act_fn,\n",
    "            nn.Conv2d(2*out_channels, 2*out_channels, 3, padding=1),\n",
    "            act_fn,\n",
    "            nn.Conv2d(2*out_channels, 4*out_channels, 3, padding=1, stride=2), # (8, 8)\n",
    "            act_fn,\n",
    "            nn.Conv2d(4*out_channels, 4*out_channels, 3, padding=1),\n",
    "            act_fn,\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(4*out_channels*8*8, latent_dim),\n",
    "            act_fn\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 3, 60, 60)\n",
    "        output = self.net(x)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "  def __init__(self, in_channels=1, out_channels=16, latent_dim=200, act_fn=nn.LeakyReLU()):\n",
    "    super().__init__()\n",
    "\n",
    "    self.out_channels = out_channels\n",
    "\n",
    "    self.linear = nn.Sequential(\n",
    "        nn.Linear(latent_dim, 4*out_channels*8*8),\n",
    "        act_fn\n",
    "    )\n",
    "\n",
    "    self.conv = nn.Sequential(\n",
    "        nn.ConvTranspose2d(4*out_channels, 4*out_channels, 3, padding=1), # (8, 8)\n",
    "        act_fn,\n",
    "        nn.ConvTranspose2d(4*out_channels, 2*out_channels, 3, padding=1, \n",
    "                           stride=2, output_padding=1), # (16, 16)\n",
    "        act_fn,\n",
    "        nn.ConvTranspose2d(2*out_channels, 2*out_channels, 3, padding=1),\n",
    "        act_fn,\n",
    "        nn.ConvTranspose2d(2*out_channels, out_channels, 3, padding=1, \n",
    "                           stride=2, output_padding=1), # (32, 32)\n",
    "        act_fn,\n",
    "        nn.ConvTranspose2d(out_channels, out_channels, 3, padding=1),\n",
    "        act_fn,\n",
    "        nn.ConvTranspose2d(out_channels, in_channels, 3, padding=1)\n",
    "    )\n",
    "\n",
    "  def forward(self, x):\n",
    "    output = self.linear(x)\n",
    "    output = output.view(-1, 4*self.out_channels, 8, 8)\n",
    "    output = self.conv(output)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Autoencoder(nn.Module):\n",
    "  def __init__(self, encoder, decoder):\n",
    "    super().__init__()\n",
    "    self.encoder = encoder\n",
    "    self.encoder.to(device)\n",
    "\n",
    "    self.decoder = decoder\n",
    "    self.decoder.to(device)\n",
    "\n",
    "  def forward(self, x):\n",
    "    encoded = self.encoder(x)\n",
    "    decoded = self.decoder(encoded)\n",
    "    return decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvolutionalAutoencoder():\n",
    "  def __init__(self, autoencoder):\n",
    "    self.network = autoencoder\n",
    "    self.optimizer = torch.optim.Adam(self.network.parameters(), lr=1e-3)\n",
    "\n",
    "  def train(self, loss_function, epochs, batch_size, \n",
    "            training_set, validation_set, test_set):\n",
    "    \n",
    "    #  creating log\n",
    "    log_dict = {\n",
    "        'training_loss_per_batch': [],\n",
    "        'validation_loss_per_batch': [],\n",
    "        'visualizations': []\n",
    "    } \n",
    "\n",
    "    #  defining weight initialization function\n",
    "    def init_weights(module):\n",
    "      if isinstance(module, nn.Conv2d):\n",
    "        torch.nn.init.xavier_uniform_(module.weight)\n",
    "        module.bias.data.fill_(0.01)\n",
    "      elif isinstance(module, nn.Linear):\n",
    "        torch.nn.init.xavier_uniform_(module.weight)\n",
    "        module.bias.data.fill_(0.01)\n",
    "\n",
    "    #  initializing network weights\n",
    "    self.network.apply(init_weights)\n",
    "\n",
    "\n",
    "    #  setting convnet to training mode\n",
    "    self.network.train()\n",
    "    self.network.to(device)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "      print(f'Epoch {epoch+1}/{epochs}')\n",
    "      train_losses = []\n",
    "\n",
    "      #------------\n",
    "      #  TRAINING\n",
    "      #------------\n",
    "      print('training...')\n",
    "      for images in tqdm(train_loader):\n",
    "        #  zeroing gradients\n",
    "        self.optimizer.zero_grad()\n",
    "        #  sending images to device\n",
    "        images = images.to(device)\n",
    "        #  reconstructing images\n",
    "        output = self.network(images)\n",
    "        #  computing loss\n",
    "        loss = loss_function(output, images.view(-1, 3, 32, 32))\n",
    "        #  calculating gradients\n",
    "        loss.backward()\n",
    "        #  optimizing weights\n",
    "        self.optimizer.step()\n",
    "\n",
    "        #--------------\n",
    "        # LOGGING\n",
    "        #--------------\n",
    "        log_dict['training_loss_per_batch'].append(loss.item())\n",
    "\n",
    "      #--------------\n",
    "      # VALIDATION\n",
    "      #--------------\n",
    "      print('validating...')\n",
    "      for val_images in tqdm(test_loader):\n",
    "        with torch.no_grad():\n",
    "          #  sending validation images to device\n",
    "          val_images = val_images.to(device)\n",
    "          #  reconstructing images\n",
    "          output = self.network(val_images)\n",
    "          #  computing validation loss\n",
    "          val_loss = loss_function(output, val_images.view(-1, 3, 32, 32))\n",
    "\n",
    "        #--------------\n",
    "        # LOGGING\n",
    "        #--------------\n",
    "        log_dict['validation_loss_per_batch'].append(val_loss.item())\n",
    "\n",
    "\n",
    "      #--------------\n",
    "      # VISUALISATION\n",
    "      #--------------\n",
    "      print(f'training_loss: {round(loss.item(), 4)} validation_loss: {round(val_loss.item(), 4)}')\n",
    "\n",
    "      for test_images in test_loader:\n",
    "        #  sending test images to device\n",
    "        test_images = test_images.to(device)\n",
    "        with torch.no_grad():\n",
    "          #  reconstructing test images\n",
    "          reconstructed_imgs = self.network(test_images)\n",
    "        #  sending reconstructed and images to cpu to allow for visualization\n",
    "        reconstructed_imgs = reconstructed_imgs.cpu()\n",
    "        test_images = test_images.cpu()\n",
    "\n",
    "        #  visualisation\n",
    "        imgs = torch.stack([test_images.view(-1, 3, 32, 32), reconstructed_imgs], \n",
    "                          dim=1).flatten(0,1)\n",
    "        grid = make_grid(imgs, nrow=10, normalize=True, padding=1)\n",
    "        grid = grid.permute(1, 2, 0)\n",
    "        plt.figure(dpi=170)\n",
    "        plt.title('Original/Reconstructed')\n",
    "        plt.imshow(grid)\n",
    "        log_dict['visualizations'].append(grid)\n",
    "        plt.axis('off')\n",
    "        plt.show()\n",
    "      \n",
    "    return log_dict\n",
    "\n",
    "  def autoencode(self, x):\n",
    "    return self.network(x)\n",
    "\n",
    "  def encode(self, x):\n",
    "    encoder = self.network.encoder\n",
    "    return encoder(x)\n",
    "  \n",
    "  def decode(self, x):\n",
    "    decoder = self.network.decoder\n",
    "    return decoder(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  training model\n",
    "model = ConvolutionalAutoencoder(Autoencoder(Encoder(), Decoder()))\n",
    "\n",
    "log_dict = model.train(nn.MSELoss(), epochs=10, batch_size=64, \n",
    "                       training_set=dataset, validation_set=dataset,\n",
    "                       test_set=test_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
